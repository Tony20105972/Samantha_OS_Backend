{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tony20105972/Samantha_OS_Backend/blob/main/LangGraph_Flow_Runner.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers accelerate bitsandbytes -q\n",
        "!pip install --upgrade huggingface_hub -q\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BOjTtrKMfd6T",
        "outputId": "75eccb9a-a29b-422c-fe26-26bdf36a115d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.9/72.9 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m37.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m50.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# phi3_langgraph_runner.py\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import torch\n",
        "from typing import TypedDict, Optional\n",
        "import os\n",
        "\n",
        "# 1. ✅ 상태 정의\n",
        "class AgentState(TypedDict):\n",
        "    prompt: str\n",
        "    result: Optional[str]\n",
        "\n",
        "# 2. ✅ 모델 로딩 (SaaS 수준 성능 최적화 포함)\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/phi-3-mini-4k-instruct\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"microsoft/phi-3-mini-4k-instruct\",\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "model.config.attn_implementation = \"eager\"  # 호환성 확보\n",
        "\n",
        "# 3. ✅ Node 정의 (LangGraph 스타일)\n",
        "def phi3_node(state: AgentState) -> AgentState:\n",
        "    prompt = state[\"prompt\"]\n",
        "    if not prompt:\n",
        "        return {**state, \"result\": \"❌ No prompt provided.\"}\n",
        "\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "    try:\n",
        "        outputs = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=256,\n",
        "            temperature=0.7,\n",
        "            do_sample=True,\n",
        "        )\n",
        "        result = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "        return {**state, \"result\": result}\n",
        "    except Exception as e:\n",
        "        return {**state, \"result\": f\"❌ Error: {str(e)}\"}\n",
        "\n",
        "# 4. ✅ 헌법 검사기 (선택)\n",
        "def rule_checker(state: AgentState) -> AgentState:\n",
        "    # 예: 금지어 검사 등\n",
        "    forbidden = [\"violence\", \"harm\"]\n",
        "    if any(word in (state[\"result\"] or \"\").lower() for word in forbidden):\n",
        "        return {**state, \"result\": \"❌ Rule Violation Detected.\"}\n",
        "    return state\n",
        "\n",
        "# 5. ✅ 외부 출력 처리기\n",
        "def external_output(state: AgentState):\n",
        "    print(\"✅ Final Output:\", state[\"result\"])\n",
        "    # 예: Slack 전송, HTML 저장 등 SaaS용 확장 가능\n",
        "\n",
        "# 6. ✅ 실행 흐름 (LangGraph 스타일)\n",
        "def run_agent_flow(prompt: str):\n",
        "    state: AgentState = {\"prompt\": prompt, \"result\": None}\n",
        "    state = phi3_node(state)\n",
        "    state = rule_checker(state)\n",
        "    external_output(state)\n",
        "    return state\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87,
          "referenced_widgets": [
            "ada20eb6a06b4ec6b4c0d7185258bba0",
            "fa2d91594a7c49a0967ef242f96f460d",
            "e0faa5ad09bb478c8c9259689af743d4",
            "a1d07503315f479aa6a4e98fb57f9c0a",
            "811fd9fc89fa4d1fb533cfd47af1fed3",
            "cd5f6aabe56e4f049948ccab5c961c2b",
            "0fb1f4e18d2a43eab127bc54d89f6b91",
            "400d80e4d7304c25be874d8f94595f37",
            "dbbbec7505274a7dbbbbdb0d33ecaefe",
            "d93e98cc17384734bf766fb6c3870a7d",
            "966da22839d140469a79a615a9c4fd62"
          ]
        },
        "id": "UuwDtowefe4n",
        "outputId": "836ba5d3-a383-4d83-fc02-830aadf0424c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ada20eb6a06b4ec6b4c0d7185258bba0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:accelerate.big_modeling:Some parameters are on the meta device because they were offloaded to the disk and cpu.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import uuid\n",
        "import time\n",
        "from collections import deque\n",
        "\n",
        "class LangGraphRunner:\n",
        "    \"\"\"\n",
        "    LangGraph 흐름을 시뮬레이션하고 실행하는 클래스입니다.\n",
        "    사용자가 정의한 노드와 엣지를 기반으로 에이전트 워크플로우를 실행합니다.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, flow_filepath='sample_flow.json', constitution_filepath='constitution.json'):\n",
        "        \"\"\"\n",
        "        초기화 메서드: 흐름 정의와 헌법(규칙)을 로드합니다.\n",
        "\n",
        "        Args:\n",
        "            flow_filepath (str): LangGraph 흐름 정의가 담긴 JSON 파일 경로.\n",
        "            constitution_filepath (str): 헌법(규칙) 정의가 담긴 JSON 파일 경로.\n",
        "        \"\"\"\n",
        "        self.flow_definition = self._load_json(flow_filepath)\n",
        "        self.constitution = self._load_json(constitution_filepath)\n",
        "        self.nodes = {node['id']: node for node in self.flow_definition.get('nodes', [])}\n",
        "        self.edges = self.flow_definition.get('edges', [])\n",
        "        print(f\"흐름 정의 로드 완료: {len(self.nodes)}개 노드, {len(self.edges)}개 엣지\")\n",
        "        print(f\"헌법 정의 로드 완료: {len(self.constitution.get('rules', []))}개 규칙\")\n",
        "\n",
        "    def _load_json(self, filepath):\n",
        "        \"\"\"JSON 파일을 로드합니다.\"\"\"\n",
        "        try:\n",
        "            with open(filepath, 'r', encoding='utf-8') as f:\n",
        "                return json.load(f)\n",
        "        except FileNotFoundError:\n",
        "            print(f\"오류: 파일을 찾을 수 없습니다 - {filepath}\")\n",
        "            return {}\n",
        "        except json.JSONDecodeError:\n",
        "            print(f\"오류: JSON 디코딩 실패 - {filepath}\")\n",
        "            return {}\n",
        "\n",
        "    def _execute_node(self, node_id, current_state, execution_log):\n",
        "        \"\"\"\n",
        "        단일 노드의 로직을 실행하고 상태를 업데이트합니다.\n",
        "        (이 부분은 시뮬레이션을 위한 더미 로직입니다.)\n",
        "\n",
        "        Args:\n",
        "            node_id (str): 현재 실행할 노드의 ID.\n",
        "            current_state (dict): 현재 워크플로우의 상태 변수 딕셔너리.\n",
        "            execution_log (list): 실행 로그를 기록할 리스트.\n",
        "\n",
        "        Returns:\n",
        "            dict: 업데이트된 상태 변수.\n",
        "            str: 다음 노드로의 라우팅 결정 (ROUTER 노드 전용).\n",
        "            bool: 규칙 위반 여부 (RULE_CHECKER 노드 전용).\n",
        "        \"\"\"\n",
        "        node = self.nodes.get(node_id)\n",
        "        if not node:\n",
        "            print(f\"경고: 노드를 찾을 수 없습니다 - {node_id}\")\n",
        "            return current_state, None, False\n",
        "\n",
        "        node_type = node['type']\n",
        "        node_label = node['label']\n",
        "        properties = node.get('properties', {})\n",
        "        output_vars = properties.get('outputVars', '')\n",
        "        input_vars = properties.get('inputVars', '')\n",
        "\n",
        "        print(f\"\\n--- 노드 실행: [{node_type}] {node_label} (ID: {node_id}) ---\")\n",
        "        log_entry = {\n",
        "            \"timestamp\": time.time(),\n",
        "            \"node_id\": node_id,\n",
        "            \"node_type\": node_type,\n",
        "            \"node_label\": node_label,\n",
        "            \"input_state_before_execution\": current_state.copy(),\n",
        "            \"output_data\": {}\n",
        "        }\n",
        "\n",
        "        next_route = None\n",
        "        rule_violation = False\n",
        "\n",
        "        if node_type == 'STATE':\n",
        "            # 초기 상태 변수 설정 (예: initial_topic)\n",
        "            for key, value in properties.items():\n",
        "                if key.startswith('initial_'):\n",
        "                    var_name = key[len('initial_'):]\n",
        "                    current_state[var_name] = value\n",
        "                    log_entry[\"output_data\"][var_name] = value\n",
        "            print(f\"초기 상태 설정: {current_state}\")\n",
        "\n",
        "        elif node_type == 'LLM':\n",
        "            prompt_template = properties.get('promptTemplate', '')\n",
        "            # 입력 변수 가져오기\n",
        "            input_values = {var: current_state.get(var, f\"<{var} 없음>\") for var in input_vars.split(',') if var}\n",
        "            # 프롬프트 템플릿 채우기 (간단한 시뮬레이션)\n",
        "            generated_content = prompt_template\n",
        "            for var, val in input_values.items():\n",
        "                generated_content = generated_content.replace(f\"{{{var}}}\", str(val))\n",
        "\n",
        "            # LLM 결과 시뮬레이션\n",
        "            llm_output = f\"생성된 콘텐츠: '{generated_content}' (온도: {properties.get('temperature')})\"\n",
        "            if output_vars:\n",
        "                current_state[output_vars] = llm_output\n",
        "                log_entry[\"output_data\"][output_vars] = llm_output\n",
        "            print(f\"LLM 출력: {llm_output}\")\n",
        "\n",
        "        elif node_type == 'TOOL':\n",
        "            tool_name = properties.get('toolName', '기본 도구')\n",
        "            params_str = properties.get('params', '{}')\n",
        "            try:\n",
        "                params = json.loads(params_str)\n",
        "            except json.JSONDecodeError:\n",
        "                params = {}\n",
        "            input_values = {var: current_state.get(var, f\"<{var} 없음>\") for var in input_vars.split(',') if var}\n",
        "\n",
        "            # 도구 실행 시뮬레이션\n",
        "            tool_result = f\"'{tool_name}' 도구 실행 완료. 입력: {input_values}, 파라미터: {params}\"\n",
        "            if output_vars:\n",
        "                current_state[output_vars] = tool_result\n",
        "                log_entry[\"output_data\"][output_vars] = tool_result\n",
        "            print(f\"도구 출력: {tool_result}\")\n",
        "\n",
        "        elif node_type == 'ROUTER':\n",
        "            condition_logic = properties.get('conditionLogic', '')\n",
        "            input_value_for_router = current_state.get(input_vars, None) # 라우터 입력 변수\n",
        "\n",
        "            # 라우터 조건 로직 시뮬레이션\n",
        "            # 실제로는 복잡한 조건 파싱 및 평가 필요\n",
        "            if \"if\" in condition_logic and \"==\" in condition_logic and \"->\" in condition_logic:\n",
        "                try:\n",
        "                    # 예시: \"if is_valid == false -> to node_llm_rewrite\"\n",
        "                    condition_part = condition_logic.split(\"->\")[0].strip()\n",
        "                    decision_part = condition_logic.split(\"->\")[1].strip()\n",
        "\n",
        "                    # 간단한 조건 평가 시뮬레이션 (is_valid == false)\n",
        "                    if \"is_valid == false\" in condition_part and input_value_for_router == False:\n",
        "                        next_route = \"invalid\" # 예시 라우팅 결정\n",
        "                    elif \"is_valid == true\" in condition_part and input_value_for_router == True:\n",
        "                        next_route = \"valid\" # 예시 라우팅 결정\n",
        "                    else:\n",
        "                        next_route = \"default\" # 조건 불일치 시 기본 경로\n",
        "                except Exception as e:\n",
        "                    print(f\"라우터 로직 파싱 오류: {e}\")\n",
        "                    next_route = \"error\"\n",
        "            else:\n",
        "                next_route = \"default\" # 기본 라우팅\n",
        "\n",
        "            if output_vars:\n",
        "                current_state[output_vars] = next_route\n",
        "                log_entry[\"output_data\"][output_vars] = next_route\n",
        "            print(f\"라우터 결정: {next_route}\")\n",
        "\n",
        "        elif node_type == 'RULE_CHECKER':\n",
        "            rule_set_name = properties.get('ruleSetName', '')\n",
        "            input_value_for_rule = current_state.get(input_vars, '')\n",
        "\n",
        "            # 헌법(규칙)을 기반으로 규칙 검사 시뮬레이션\n",
        "            # 실제로는 constitution.json의 'logic' 필드를 파싱하여 평가해야 함\n",
        "            rule_found = False\n",
        "            for rule in self.constitution.get('rules', []):\n",
        "                if rule['name'] == rule_set_name:\n",
        "                    rule_found = True\n",
        "                    # 시뮬레이션을 위해 'no_bias' 규칙은 항상 위반으로 가정\n",
        "                    # 'content_length' 규칙은 입력 길이에 따라 다르게 가정\n",
        "                    if rule_set_name == \"no_bias\":\n",
        "                        rule_violation = True # 항상 위반으로 시뮬레이션\n",
        "                        print(f\"규칙 '{rule_set_name}' 검사: 위반 (시뮬레이션)\")\n",
        "                    elif rule_set_name == \"content_length\":\n",
        "                        if isinstance(input_value_for_rule, str) and len(input_value_for_rule.split()) < 500:\n",
        "                            rule_violation = True\n",
        "                            print(f\"규칙 '{rule_set_name}' 검사: 위반 (콘텐츠 길이 부족)\")\n",
        "                        else:\n",
        "                            rule_violation = False\n",
        "                            print(f\"규칙 '{rule_set_name}' 검사: 통과 (콘텐츠 길이 충분)\")\n",
        "                    else:\n",
        "                        rule_violation = False # 다른 규칙은 통과로 시뮬레이션\n",
        "                        print(f\"규칙 '{rule_set_name}' 검사: 통과 (기본)\")\n",
        "                    break\n",
        "            if not rule_found:\n",
        "                print(f\"경고: 규칙 세트 '{rule_set_name}'를 헌법에서 찾을 수 없습니다. 기본적으로 통과 처리.\")\n",
        "                rule_violation = False\n",
        "\n",
        "            is_valid = not rule_violation # is_valid는 위반이 아니면 True\n",
        "            if output_vars:\n",
        "                current_state[output_vars] = is_valid\n",
        "                log_entry[\"output_data\"][output_vars] = is_valid\n",
        "            print(f\"규칙 검사 결과 (is_valid): {is_valid}\")\n",
        "\n",
        "\n",
        "        elif node_type == 'OUTPUT':\n",
        "            output_type = properties.get('outputType', 'Webhook')\n",
        "            target_url = properties.get('targetUrl', '')\n",
        "            send_vars = properties.get('sendVars', '')\n",
        "            output_data = {var: current_state.get(var, f\"<{var} 없음>\") for var in send_vars.split(',') if var}\n",
        "\n",
        "            # 최종 출력 시뮬레이션\n",
        "            print(f\"최종 출력 노드: 타입={output_type}, 대상={target_url}, 데이터={output_data}\")\n",
        "            log_entry[\"output_data\"] = output_data\n",
        "\n",
        "        log_entry[\"output_state_after_execution\"] = current_state.copy()\n",
        "        execution_log.append(log_entry)\n",
        "        return current_state, next_route, rule_violation\n",
        "\n",
        "    def run_flow(self, initial_inputs={}):\n",
        "        \"\"\"\n",
        "        정의된 흐름을 시작부터 끝까지 실행합니다.\n",
        "\n",
        "        Args:\n",
        "            initial_inputs (dict): 흐름 시작 시 주입할 초기 입력 변수.\n",
        "\n",
        "        Returns:\n",
        "            dict: 최종 상태 변수.\n",
        "            list: 전체 실행 로그.\n",
        "            list: 규칙 위반이 발생한 엣지 목록.\n",
        "        \"\"\"\n",
        "        current_state = initial_inputs.copy()\n",
        "        execution_log = []\n",
        "        violated_edges = []\n",
        "\n",
        "        # 시작 노드 찾기 (STATE 타입 노드를 시작 노드로 간주)\n",
        "        start_node_id = None\n",
        "        for node_id, node_data in self.nodes.items():\n",
        "            if node_data.get('type') == 'STATE':\n",
        "                start_node_id = node_id\n",
        "                break\n",
        "\n",
        "        if not start_node_id:\n",
        "            print(\"오류: 시작 STATE 노드를 찾을 수 없습니다. 흐름을 시작할 수 없습니다.\")\n",
        "            return current_state, execution_log, violated_edges\n",
        "\n",
        "        current_node_id = start_node_id\n",
        "        visited_nodes = set() # 무한 루프 방지\n",
        "\n",
        "        # BFS (너비 우선 탐색) 또는 DFS (깊이 우선 탐색) 대신,\n",
        "        # 단순 선형 흐름을 가정하고 라우터 노드에서 분기 처리\n",
        "        # 복잡한 그래프 순회는 실제 LangGraph 로직이 필요\n",
        "\n",
        "        # 현재는 시작 노드부터 엣지를 따라 순차적으로 실행하는 방식으로 시뮬레이션\n",
        "        # 실제 LangGraph는 더 복잡한 그래프 순회 로직을 가짐.\n",
        "        # 이 시뮬레이션은 'Router' 노드를 통한 조건부 분기만 처리\n",
        "\n",
        "        # 현재 노드에서 다음 노드를 찾기 위한 큐\n",
        "        queue = deque([current_node_id])\n",
        "\n",
        "        while queue:\n",
        "            node_to_execute_id = queue.popleft()\n",
        "\n",
        "            if node_to_execute_id in visited_nodes:\n",
        "                # 이미 방문한 노드 (루프 발생 가능성)\n",
        "                # 이 시뮬레이션에서는 단순 루프를 방지하지만, 실제 LangGraph는 더 복잡한 루프 처리 로직 가짐\n",
        "                print(f\"경고: 노드 '{node_to_execute_id}'는 이미 방문했습니다. 루프 방지를 위해 건너뜁니다.\")\n",
        "                continue\n",
        "\n",
        "            visited_nodes.add(node_to_execute_id)\n",
        "\n",
        "            node_data = self.nodes.get(node_to_execute_id)\n",
        "            if not node_data:\n",
        "                print(f\"오류: 존재하지 않는 노드 ID: {node_to_execute_id}\")\n",
        "                continue\n",
        "\n",
        "            current_state, router_decision, rule_violation_flag = self._execute_node(\n",
        "                node_to_execute_id, current_state, execution_log\n",
        "            )\n",
        "\n",
        "            if rule_violation_flag:\n",
        "                # 규칙 위반이 발생한 엣지를 찾아서 기록 (시뮬레이션)\n",
        "                # 실제로는 해당 노드와 연결된 모든 엣지를 위반으로 표시할 수 있음\n",
        "                for edge in self.edges:\n",
        "                    if edge['source'] == node_to_execute_id:\n",
        "                        violated_edges.append(edge['id'])\n",
        "                        print(f\"규칙 위반 엣지 기록: {edge['id']}\")\n",
        "                        break # 첫 번째 위반 엣지만 기록 (예시)\n",
        "\n",
        "            # 다음 노드 결정 로직\n",
        "            next_edges = [e for e in self.edges if e['source'] == node_to_execute_id]\n",
        "\n",
        "            if node_data['type'] == 'ROUTER':\n",
        "                # 라우터 노드는 결정에 따라 다음 엣지를 선택\n",
        "                found_next_edge = False\n",
        "                for edge in next_edges:\n",
        "                    condition = edge.get('condition')\n",
        "                    if condition:\n",
        "                        # 조건 파싱 및 평가 (간단한 시뮬레이션)\n",
        "                        # 예: \"decision_path == 'valid'\"\n",
        "                        if f\"decision_path == '{router_decision}'\" in condition:\n",
        "                            queue.append(edge['target'])\n",
        "                            print(f\"라우터 결정에 따라 다음 노드: {edge['target']}\")\n",
        "                            found_next_edge = True\n",
        "                            break\n",
        "                    # 조건이 없거나 조건에 맞지 않으면 기본 엣지 (첫 번째 엣지)\n",
        "                if not found_next_edge and next_edges:\n",
        "                    # 라우터 조건에 맞는 엣지가 없으면 첫 번째 엣지를 기본으로 선택\n",
        "                    queue.append(next_edges[0]['target'])\n",
        "                    print(f\"라우터 조건 불일치, 기본 다음 노드: {next_edges[0]['target']}\")\n",
        "\n",
        "            elif node_data['type'] == 'OUTPUT':\n",
        "                # Output 노드는 흐름의 끝이므로 더 이상 진행하지 않음\n",
        "                print(f\"흐름 종료: Output 노드 '{node_to_execute_id}' 도달.\")\n",
        "                break # 흐름 종료\n",
        "\n",
        "            else:\n",
        "                # 일반 노드는 연결된 모든 다음 엣지를 따라감 (단순 시뮬레이션)\n",
        "                # 실제 LangGraph는 다음 상태를 정확히 정의해야 함\n",
        "                for edge in next_edges:\n",
        "                    # 엣지에 조건이 없는 경우에만 추가 (라우터가 아닌 일반 노드)\n",
        "                    if 'condition' not in edge or not edge['condition']:\n",
        "                        queue.append(edge['target'])\n",
        "                        print(f\"다음 노드: {edge['target']}\")\n",
        "                if not next_edges:\n",
        "                    print(f\"경고: 노드 '{node_to_execute_id}'에 연결된 다음 엣지가 없습니다. 흐름 중단.\")\n",
        "                    break\n",
        "\n",
        "\n",
        "        print(\"\\n=== 흐름 실행 완료 ===\")\n",
        "        print(f\"최종 상태: {current_state}\")\n",
        "        print(f\"규칙 위반 엣지 ID: {violated_edges}\")\n",
        "        return current_state, execution_log, violated_edges\n",
        "\n",
        "# --- JSON 파일 생성 (실행을 위해 필요) ---\n",
        "# sample_flow.json\n",
        "sample_flow_content = {\n",
        "  \"nodes\": [\n",
        "    {\"id\": \"node_start\", \"type\": \"STATE\", \"label\": \"시작 상태\", \"properties\": {\"initial_topic\": \"Web3 AI 에이전트의 미래\"}},\n",
        "    {\"id\": \"node_llm_blog\", \"type\": \"LLM\", \"label\": \"블로그 글 생성\", \"properties\": {\"promptTemplate\": \"주제: {topic}에 대한 500자 블로그 초안 작성\", \"temperature\": 0.7, \"inputVars\": \"topic\", \"outputVars\": \"blog_post_draft\"}},\n",
        "    {\"id\": \"node_rule_check\", \"type\": \"RULE_CHECKER\", \"label\": \"편향성 검사\", \"properties\": {\"ruleSetName\": \"no_bias\", \"inputVars\": \"blog_post_draft\", \"outputVars\": \"is_valid\"}},\n",
        "    {\"id\": \"node_router_decision\", \"type\": \"ROUTER\", \"label\": \"편향성 라우터\", \"properties\": {\"conditionLogic\": \"if is_valid == false -> to node_llm_rewrite\", \"inputVars\": \"is_valid\", \"outputVars\": \"decision_path\"}},\n",
        "    {\"id\": \"node_llm_rewrite\", \"type\": \"LLM\", \"label\": \"블로그 글 수정\", \"properties\": {\"promptTemplate\": \"다음 블로그 글에서 편향성을 제거하고 다시 작성: {blog_post_draft}\", \"temperature\": 0.5, \"inputVars\": \"blog_post_draft\", \"outputVars\": \"blog_post_final\"}},\n",
        "    {\"id\": \"node_output_publish\", \"type\": \"OUTPUT\", \"label\": \"블로그 발행\", \"properties\": {\"outputType\": \"Webhook\", \"targetUrl\": \"https://agentlayer.com/publish\", \"sendVars\": \"blog_post_final\"}},\n",
        "    {\"id\": \"node_output_alert\", \"type\": \"OUTPUT\", \"label\": \"알림 전송\", \"properties\": {\"outputType\": \"Slack\", \"targetUrl\": \"https://hooks.slack.com/alert\", \"sendVars\": \"blog_post_draft\"}}\n",
        "  ],\n",
        "  \"edges\": [\n",
        "    {\"id\": \"edge_1\", \"source\": \"node_start\", \"target\": \"node_llm_blog\"},\n",
        "    {\"id\": \"edge_2\", \"source\": \"node_llm_blog\", \"target\": \"node_rule_check\"},\n",
        "    {\"id\": \"edge_3\", \"source\": \"node_rule_check\", \"target\": \"node_router_decision\"}, # Completed edge_3\n",
        "    {\"id\": \"edge_4\", \"source\": \"node_router_decision\", \"target\": \"node_llm_rewrite\", \"condition\": \"decision_path == 'invalid'\"}, # Added missing edges and conditions\n",
        "    {\"id\": \"edge_5\", \"source\": \"node_router_decision\", \"target\": \"node_output_publish\", \"condition\": \"decision_path == 'valid'\"},\n",
        "    {\"id\": \"edge_6\", \"source\": \"node_llm_rewrite\", \"target\": \"node_output_publish\"}\n",
        "  ]\n",
        "}\n",
        "\n",
        "\n",
        "# constitution.json\n",
        "constitution_content = {\n",
        "  \"rules\": [\n",
        "    {\"name\": \"no_bias\", \"description\": \"콘텐츠는 편향성을 포함해서는 안 됩니다.\", \"logic\": \"check_for_bias(content)\"},\n",
        "    {\"name\": \"content_length\", \"description\": \"블로그 글 길이는 최소 500 단어 이상이어야 합니다.\", \"logic\": \"len(content.split()) >= 500\"}\n",
        "  ]\n",
        "}\n",
        "\n",
        "# 파일로 저장 (실제 실행 시 필요)\n",
        "with open('sample_flow.json', 'w', encoding='utf-8') as f:\n",
        "    json.dump(sample_flow_content, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "with open('constitution.json', 'w', encoding='utf-8') as f:\n",
        "    json.dump(constitution_content, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "print(\"JSON 파일 생성 완료: sample_flow.json, constitution.json\")\n",
        "\n",
        "# LangGraphRunner 인스턴스 생성 및 실행\n",
        "runner = LangGraphRunner()\n",
        "final_state, execution_log, violated_edges = runner.run_flow()\n",
        "\n",
        "# 결과 출력\n",
        "print(\"\\n--- 최종 결과 ---\")\n",
        "print(f\"최종 상태: {final_state}\")\n",
        "print(\"\\n--- 실행 로그 ---\")\n",
        "for entry in execution_log:\n",
        "    print(f\"노드 ID: {entry['node_id']}, 타입: {entry['node_type']}, 레이블: {entry['node_label']}\")\n",
        "    print(f\"  입력 상태: {entry['input_state_before_execution']}\")\n",
        "    print(f\"  출력 데이터: {entry['output_data']}\")\n",
        "    print(f\"  출력 상태: {entry['output_state_after_execution']}\")\n",
        "print(f\"\\n규칙 위반 엣지 ID: {violated_edges}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "JSON 파일 생성 완료: sample_flow.json, constitution.json\n",
            "흐름 정의 로드 완료: 7개 노드, 6개 엣지\n",
            "헌법 정의 로드 완료: 2개 규칙\n",
            "\n",
            "--- 노드 실행: [STATE] 시작 상태 (ID: node_start) ---\n",
            "초기 상태 설정: {'topic': 'Web3 AI 에이전트의 미래'}\n",
            "다음 노드: node_llm_blog\n",
            "\n",
            "--- 노드 실행: [LLM] 블로그 글 생성 (ID: node_llm_blog) ---\n",
            "LLM 출력: 생성된 콘텐츠: '주제: Web3 AI 에이전트의 미래에 대한 500자 블로그 초안 작성' (온도: 0.7)\n",
            "다음 노드: node_rule_check\n",
            "\n",
            "--- 노드 실행: [RULE_CHECKER] 편향성 검사 (ID: node_rule_check) ---\n",
            "규칙 'no_bias' 검사: 위반 (시뮬레이션)\n",
            "규칙 검사 결과 (is_valid): False\n",
            "규칙 위반 엣지 기록: edge_3\n",
            "다음 노드: node_router_decision\n",
            "\n",
            "--- 노드 실행: [ROUTER] 편향성 라우터 (ID: node_router_decision) ---\n",
            "라우터 결정: invalid\n",
            "라우터 결정에 따라 다음 노드: node_llm_rewrite\n",
            "\n",
            "--- 노드 실행: [LLM] 블로그 글 수정 (ID: node_llm_rewrite) ---\n",
            "LLM 출력: 생성된 콘텐츠: '다음 블로그 글에서 편향성을 제거하고 다시 작성: 생성된 콘텐츠: '주제: Web3 AI 에이전트의 미래에 대한 500자 블로그 초안 작성' (온도: 0.7)' (온도: 0.5)\n",
            "다음 노드: node_output_publish\n",
            "\n",
            "--- 노드 실행: [OUTPUT] 블로그 발행 (ID: node_output_publish) ---\n",
            "최종 출력 노드: 타입=Webhook, 대상=https://agentlayer.com/publish, 데이터={'blog_post_final': \"생성된 콘텐츠: '다음 블로그 글에서 편향성을 제거하고 다시 작성: 생성된 콘텐츠: '주제: Web3 AI 에이전트의 미래에 대한 500자 블로그 초안 작성' (온도: 0.7)' (온도: 0.5)\"}\n",
            "흐름 종료: Output 노드 'node_output_publish' 도달.\n",
            "\n",
            "=== 흐름 실행 완료 ===\n",
            "최종 상태: {'topic': 'Web3 AI 에이전트의 미래', 'blog_post_draft': \"생성된 콘텐츠: '주제: Web3 AI 에이전트의 미래에 대한 500자 블로그 초안 작성' (온도: 0.7)\", 'is_valid': False, 'decision_path': 'invalid', 'blog_post_final': \"생성된 콘텐츠: '다음 블로그 글에서 편향성을 제거하고 다시 작성: 생성된 콘텐츠: '주제: Web3 AI 에이전트의 미래에 대한 500자 블로그 초안 작성' (온도: 0.7)' (온도: 0.5)\"}\n",
            "규칙 위반 엣지 ID: ['edge_3']\n",
            "\n",
            "--- 최종 결과 ---\n",
            "최종 상태: {'topic': 'Web3 AI 에이전트의 미래', 'blog_post_draft': \"생성된 콘텐츠: '주제: Web3 AI 에이전트의 미래에 대한 500자 블로그 초안 작성' (온도: 0.7)\", 'is_valid': False, 'decision_path': 'invalid', 'blog_post_final': \"생성된 콘텐츠: '다음 블로그 글에서 편향성을 제거하고 다시 작성: 생성된 콘텐츠: '주제: Web3 AI 에이전트의 미래에 대한 500자 블로그 초안 작성' (온도: 0.7)' (온도: 0.5)\"}\n",
            "\n",
            "--- 실행 로그 ---\n",
            "노드 ID: node_start, 타입: STATE, 레이블: 시작 상태\n",
            "  입력 상태: {}\n",
            "  출력 데이터: {'topic': 'Web3 AI 에이전트의 미래'}\n",
            "  출력 상태: {'topic': 'Web3 AI 에이전트의 미래'}\n",
            "노드 ID: node_llm_blog, 타입: LLM, 레이블: 블로그 글 생성\n",
            "  입력 상태: {'topic': 'Web3 AI 에이전트의 미래'}\n",
            "  출력 데이터: {'blog_post_draft': \"생성된 콘텐츠: '주제: Web3 AI 에이전트의 미래에 대한 500자 블로그 초안 작성' (온도: 0.7)\"}\n",
            "  출력 상태: {'topic': 'Web3 AI 에이전트의 미래', 'blog_post_draft': \"생성된 콘텐츠: '주제: Web3 AI 에이전트의 미래에 대한 500자 블로그 초안 작성' (온도: 0.7)\"}\n",
            "노드 ID: node_rule_check, 타입: RULE_CHECKER, 레이블: 편향성 검사\n",
            "  입력 상태: {'topic': 'Web3 AI 에이전트의 미래', 'blog_post_draft': \"생성된 콘텐츠: '주제: Web3 AI 에이전트의 미래에 대한 500자 블로그 초안 작성' (온도: 0.7)\"}\n",
            "  출력 데이터: {'is_valid': False}\n",
            "  출력 상태: {'topic': 'Web3 AI 에이전트의 미래', 'blog_post_draft': \"생성된 콘텐츠: '주제: Web3 AI 에이전트의 미래에 대한 500자 블로그 초안 작성' (온도: 0.7)\", 'is_valid': False}\n",
            "노드 ID: node_router_decision, 타입: ROUTER, 레이블: 편향성 라우터\n",
            "  입력 상태: {'topic': 'Web3 AI 에이전트의 미래', 'blog_post_draft': \"생성된 콘텐츠: '주제: Web3 AI 에이전트의 미래에 대한 500자 블로그 초안 작성' (온도: 0.7)\", 'is_valid': False}\n",
            "  출력 데이터: {'decision_path': 'invalid'}\n",
            "  출력 상태: {'topic': 'Web3 AI 에이전트의 미래', 'blog_post_draft': \"생성된 콘텐츠: '주제: Web3 AI 에이전트의 미래에 대한 500자 블로그 초안 작성' (온도: 0.7)\", 'is_valid': False, 'decision_path': 'invalid'}\n",
            "노드 ID: node_llm_rewrite, 타입: LLM, 레이블: 블로그 글 수정\n",
            "  입력 상태: {'topic': 'Web3 AI 에이전트의 미래', 'blog_post_draft': \"생성된 콘텐츠: '주제: Web3 AI 에이전트의 미래에 대한 500자 블로그 초안 작성' (온도: 0.7)\", 'is_valid': False, 'decision_path': 'invalid'}\n",
            "  출력 데이터: {'blog_post_final': \"생성된 콘텐츠: '다음 블로그 글에서 편향성을 제거하고 다시 작성: 생성된 콘텐츠: '주제: Web3 AI 에이전트의 미래에 대한 500자 블로그 초안 작성' (온도: 0.7)' (온도: 0.5)\"}\n",
            "  출력 상태: {'topic': 'Web3 AI 에이전트의 미래', 'blog_post_draft': \"생성된 콘텐츠: '주제: Web3 AI 에이전트의 미래에 대한 500자 블로그 초안 작성' (온도: 0.7)\", 'is_valid': False, 'decision_path': 'invalid', 'blog_post_final': \"생성된 콘텐츠: '다음 블로그 글에서 편향성을 제거하고 다시 작성: 생성된 콘텐츠: '주제: Web3 AI 에이전트의 미래에 대한 500자 블로그 초안 작성' (온도: 0.7)' (온도: 0.5)\"}\n",
            "노드 ID: node_output_publish, 타입: OUTPUT, 레이블: 블로그 발행\n",
            "  입력 상태: {'topic': 'Web3 AI 에이전트의 미래', 'blog_post_draft': \"생성된 콘텐츠: '주제: Web3 AI 에이전트의 미래에 대한 500자 블로그 초안 작성' (온도: 0.7)\", 'is_valid': False, 'decision_path': 'invalid', 'blog_post_final': \"생성된 콘텐츠: '다음 블로그 글에서 편향성을 제거하고 다시 작성: 생성된 콘텐츠: '주제: Web3 AI 에이전트의 미래에 대한 500자 블로그 초안 작성' (온도: 0.7)' (온도: 0.5)\"}\n",
            "  출력 데이터: {'blog_post_final': \"생성된 콘텐츠: '다음 블로그 글에서 편향성을 제거하고 다시 작성: 생성된 콘텐츠: '주제: Web3 AI 에이전트의 미래에 대한 500자 블로그 초안 작성' (온도: 0.7)' (온도: 0.5)\"}\n",
            "  출력 상태: {'topic': 'Web3 AI 에이전트의 미래', 'blog_post_draft': \"생성된 콘텐츠: '주제: Web3 AI 에이전트의 미래에 대한 500자 블로그 초안 작성' (온도: 0.7)\", 'is_valid': False, 'decision_path': 'invalid', 'blog_post_final': \"생성된 콘텐츠: '다음 블로그 글에서 편향성을 제거하고 다시 작성: 생성된 콘텐츠: '주제: Web3 AI 에이전트의 미래에 대한 500자 블로그 초안 작성' (온도: 0.7)' (온도: 0.5)\"}\n",
            "\n",
            "규칙 위반 엣지 ID: ['edge_3']\n"
          ]
        }
      ],
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4z2aoQnxvEx",
        "outputId": "845e2204-4f2e-400d-bcb2-7abde33d1ede"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ada20eb6a06b4ec6b4c0d7185258bba0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fa2d91594a7c49a0967ef242f96f460d",
              "IPY_MODEL_e0faa5ad09bb478c8c9259689af743d4",
              "IPY_MODEL_a1d07503315f479aa6a4e98fb57f9c0a"
            ],
            "layout": "IPY_MODEL_811fd9fc89fa4d1fb533cfd47af1fed3"
          }
        },
        "fa2d91594a7c49a0967ef242f96f460d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cd5f6aabe56e4f049948ccab5c961c2b",
            "placeholder": "​",
            "style": "IPY_MODEL_0fb1f4e18d2a43eab127bc54d89f6b91",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "e0faa5ad09bb478c8c9259689af743d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_400d80e4d7304c25be874d8f94595f37",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dbbbec7505274a7dbbbbdb0d33ecaefe",
            "value": 2
          }
        },
        "a1d07503315f479aa6a4e98fb57f9c0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d93e98cc17384734bf766fb6c3870a7d",
            "placeholder": "​",
            "style": "IPY_MODEL_966da22839d140469a79a615a9c4fd62",
            "value": " 2/2 [00:24&lt;00:00, 24.98s/it]"
          }
        },
        "811fd9fc89fa4d1fb533cfd47af1fed3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd5f6aabe56e4f049948ccab5c961c2b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0fb1f4e18d2a43eab127bc54d89f6b91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "400d80e4d7304c25be874d8f94595f37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dbbbec7505274a7dbbbbdb0d33ecaefe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d93e98cc17384734bf766fb6c3870a7d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "966da22839d140469a79a615a9c4fd62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}